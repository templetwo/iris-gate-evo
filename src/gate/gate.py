"""
Lab Gate — Falsifiability, Feasibility, Novelty.

The final checkpoint before S4. Every surviving claim must pass
three criteria or be routed to human review. This is where bad
hypotheses die before they waste 20 calls in simulation.

Three criteria, all required for PASS:
  1. FALSIFIABLE — Does it have a concrete disproof condition?
  2. FEASIBLE    — Can it be tested with standard methods?
  3. NOVEL       — Does it add to knowledge, not restate textbooks?

One LLM call per gate invocation. The gate model sees all verified
claims at once and evaluates them as a batch.

PASS → S4 (hypothesis operationalization)
FAIL → Human review with failure report
"""

import asyncio
import re
import time
from dataclasses import dataclass, field, asdict
from typing import Optional

import litellm

from src.models import MODELS, VERIFY_MODEL


@dataclass
class ClaimGateResult:
    """Gate result for a single claim."""
    statement: str
    falsifiable: bool
    falsifiable_reason: str
    feasible: bool
    feasible_reason: str
    novel: bool
    novel_reason: str
    passed: bool = False

    def __post_init__(self):
        self.passed = self.falsifiable and self.feasible and self.novel


@dataclass
class GateResult:
    """Complete Lab Gate output."""
    passed: bool                     # Overall: all claims passed?
    claims: list[ClaimGateResult]    # Per-claim results
    n_passed: int = 0
    n_failed: int = 0
    total_calls: int = 1             # Always 1 call (batch evaluation)
    latency_s: float = 0.0
    recommendation: str = ""


# ── Gate prompt ──

GATE_PROMPT_TEMPLATE = """\
You are a scientific review panel evaluating whether these claims, taken together, \
constitute a testable research program worth pursuing in the lab.

RESEARCH QUESTION:
"{question}"

CONTEXT:
These claims were independently generated by {n_models} AI models responding to the same \
question WITHOUT seeing each other's outputs. The system then measured convergence:
- TYPE 0 (ESTABLISHED): 4-5 out of {n_models} models independently produced this claim
- TYPE 1 (REPLICATED): 3 out of {n_models} models independently produced this claim
- TYPE 2 (SPECULATIVE): 2 models produced this claim
- TYPE 3 (SINGULAR): Only 1 model produced this claim

TYPE 0/1 claims are convergent — multiple independent models agree on the science. \
Their value is reliability, not novelty of individual facts. The novelty lives in the \
SYNTHESIS: the specific combination, quantitative predictions, and testable protocol \
that emerges from combining convergent claims.

CLAIMS TO EVALUATE:
{claims_block}

For EACH claim, evaluate:

1. **FALSIFIABLE** — Does it specify or imply a concrete condition that would disprove it? \
A quantitative claim (Kd, EC50, membrane potential) is inherently falsifiable — the number \
can be wrong. A mechanistic claim is falsifiable if blocking the mechanism would eliminate the effect.

2. **FEASIBLE** — Can it be tested with standard laboratory methods and equipment? \
Standard cell culture, fluorescence microscopy, electrophysiology, Western blot, etc. are feasible. \
Novel organism engineering, clinical trials, or bespoke instrumentation are not.

3. **NOVEL** — Does this claim, IN THE CONTEXT OF THIS RESEARCH PROGRAM, contribute to a \
testable hypothesis that advances knowledge? A TYPE 0 claim restating "CBD binds VDAC1" is \
not individually novel, but it IS novel if it anchors a quantitative prediction about selectivity \
that hasn't been experimentally tested. Judge novelty by what the claim ENABLES, not just what it states.

Respond in EXACTLY this format for each claim (numbered to match):

CLAIM 1:
FALSIFIABLE: [YES|NO] — [one sentence reason]
FEASIBLE: [YES|NO] — [one sentence reason]
NOVEL: [YES|NO] — [one sentence reason]

CLAIM 2:
FALSIFIABLE: [YES|NO] — [one sentence reason]
FEASIBLE: [YES|NO] — [one sentence reason]
NOVEL: [YES|NO] — [one sentence reason]

(continue for all claims)

Be rigorous but not reductive. The goal is a viable lab protocol, not a literature review."""


def build_claims_block(claims: list[dict]) -> str:
    """Format claims into a numbered block for the gate prompt."""
    lines = []
    for i, c in enumerate(claims, 1):
        stmt = c.get("statement", "")
        ctype = c.get("type", "?")
        conf = c.get("confidence", "?")
        mechanism = c.get("mechanism", "")
        falsifiable = c.get("falsifiable_by", "")

        block = f"CLAIM {i}: {stmt}\n  TYPE: {ctype} | CONFIDENCE: {conf}"
        if mechanism:
            block += f"\n  MECHANISM: {mechanism}"
        if falsifiable:
            block += f"\n  FALSIFIABLE BY: {falsifiable}"
        lines.append(block)

    return "\n\n".join(lines)


def build_gate_prompt(question: str, claims: list[dict], n_models: int = 5) -> str:
    """Build the complete Lab Gate prompt."""
    claims_block = build_claims_block(claims)
    return GATE_PROMPT_TEMPLATE.format(
        question=question,
        claims_block=claims_block,
        n_models=n_models,
    )


def parse_gate_response(
    response_text: str,
    claims: list[dict],
) -> list[ClaimGateResult]:
    """Parse gate model response into per-claim results.

    Handles varied formatting from different models.
    """
    results = []

    for i, claim in enumerate(claims, 1):
        # Find this claim's block in the response
        # Look for "CLAIM N:" or just parse sequentially
        pattern = re.compile(
            rf'CLAIM\s*{i}\s*:.*?'
            rf'FALSIFIABLE\s*:\s*(YES|NO)\s*[-—]?\s*(.*?)\n'
            rf'.*?FEASIBLE\s*:\s*(YES|NO)\s*[-—]?\s*(.*?)\n'
            rf'.*?NOVEL\s*:\s*(YES|NO)\s*[-—]?\s*(.*?)(?=\nCLAIM\s*\d|\Z)',
            re.IGNORECASE | re.DOTALL,
        )

        match = pattern.search(response_text)

        if match:
            falsifiable = match.group(1).upper() == "YES"
            falsifiable_reason = match.group(2).strip()
            feasible = match.group(3).upper() == "YES"
            feasible_reason = match.group(4).strip()
            novel = match.group(5).upper() == "YES"
            novel_reason = match.group(6).strip()
        else:
            # If parsing fails, try a looser pattern for this claim
            result = _parse_claim_loose(response_text, i)
            if result:
                results.append(ClaimGateResult(
                    statement=claim["statement"],
                    **result,
                ))
                continue

            # Ultimate fallback: conservative — FAIL
            falsifiable = False
            falsifiable_reason = "Could not parse gate response"
            feasible = False
            feasible_reason = "Could not parse gate response"
            novel = False
            novel_reason = "Could not parse gate response"

        results.append(ClaimGateResult(
            statement=claim["statement"],
            falsifiable=falsifiable,
            falsifiable_reason=falsifiable_reason,
            feasible=feasible,
            feasible_reason=feasible_reason,
            novel=novel,
            novel_reason=novel_reason,
        ))

    return results


def _parse_claim_loose(text: str, claim_num: int) -> Optional[dict]:
    """Loose parsing fallback for a single claim's gate evaluation."""
    # Find the section for this claim
    start_pattern = re.compile(rf'CLAIM\s*{claim_num}\b', re.IGNORECASE)
    start_match = start_pattern.search(text)
    if not start_match:
        return None

    # Find the end (next CLAIM or end of text)
    end_pattern = re.compile(rf'CLAIM\s*{claim_num + 1}\b', re.IGNORECASE)
    end_match = end_pattern.search(text, start_match.end())
    section = text[start_match.start():end_match.start() if end_match else len(text)]

    def _extract_bool(field_name: str) -> tuple[bool, str]:
        m = re.search(
            rf'{field_name}\s*:\s*(YES|NO)\s*[-—]?\s*(.+?)(?=\n|$)',
            section, re.IGNORECASE,
        )
        if m:
            return m.group(1).upper() == "YES", m.group(2).strip()
        return False, "Not found in response"

    f_val, f_reason = _extract_bool("FALSIFIABLE")
    fe_val, fe_reason = _extract_bool("FEASIBLE")
    n_val, n_reason = _extract_bool("NOVEL")

    return {
        "falsifiable": f_val,
        "falsifiable_reason": f_reason,
        "feasible": fe_val,
        "feasible_reason": fe_reason,
        "novel": n_val,
        "novel_reason": n_reason,
    }


def evaluate_claims_offline(claims: list[dict]) -> list[ClaimGateResult]:
    """Offline fallback — passes all claims through to human review.

    When no LLM is available, we don't pretend to evaluate novelty or
    feasibility with string-length heuristics. We mark everything as
    needing human review and flag what metadata is present.
    """
    results = []
    for claim in claims:
        stmt = claim.get("statement", "")
        falsifiable_by = claim.get("falsifiable_by", "")
        mechanism = claim.get("mechanism", "")

        # Minimal checks: does the claim have the fields populated?
        has_falsifiable = bool(falsifiable_by.strip())
        has_mechanism = bool(mechanism.strip())

        results.append(ClaimGateResult(
            statement=stmt,
            falsifiable=has_falsifiable,
            falsifiable_reason="Falsification criterion provided" if has_falsifiable else "No falsification criterion specified",
            feasible=has_mechanism,
            feasible_reason="Mechanism specified" if has_mechanism else "No mechanism specified",
            novel=True,  # Don't pretend to judge novelty offline
            novel_reason="Offline mode — novelty requires model evaluation",
        ))

    return results


async def run_gate(
    pipeline_result: dict,
    model_name: str = "verify",
    use_offline: bool = False,
) -> GateResult:
    """Run the Lab Gate on verified claims.

    Uses Perplexity sonar-pro by default — it has live web access and can
    judge novelty against current literature, not just pattern-match.
    Entrust the thinking to the model, not to our heuristics.

    Args:
        pipeline_result: Output from apply_verdicts() or run_pipeline().
            Needs 'verified_claims' or 'final_claims' and 'question'.
        model_name: Which model to use. Default "verify" = Perplexity sonar-pro.
        use_offline: Use offline fallback instead of LLM call.

    Returns:
        GateResult with per-claim evaluations and overall PASS/FAIL.
    """
    question = pipeline_result.get("question", "")

    # Use verified_claims if available, otherwise final_claims
    claims = pipeline_result.get("verified_claims",
             pipeline_result.get("final_claims", []))

    # Filter: only remove contradicted claims — let the model evaluate everything
    gate_claims = [
        c for c in claims
        if not c.get("contradicted", False)
    ]

    if not gate_claims:
        return GateResult(
            passed=False,
            claims=[],
            recommendation="No claims survived for gate evaluation.",
        )

    t_start = time.monotonic()

    if use_offline:
        claim_results = evaluate_claims_offline(gate_claims)
        total_calls = 0
    else:
        # Build gate prompt and dispatch to Perplexity sonar-pro
        n_models = pipeline_result.get("n_models", 5)
        prompt = build_gate_prompt(question, gate_claims, n_models=n_models)

        # Resolve model: "verify" uses VERIFY_MODEL (Perplexity), others use MODELS
        if model_name == "verify":
            litellm_model = f"perplexity/{VERIFY_MODEL['id']}"
            kwargs = {
                "model": litellm_model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 2000,
            }
        else:
            model = MODELS.get(model_name, MODELS["claude"])
            prefix = {
                "anthropic": "anthropic/",
                "openai": "openai/",
                "xai": "openai/",
                "google": "gemini/",
                "deepseek": "openai/",
            }.get(model["provider"], "openai/")

            kwargs = {
                "model": f"{prefix}{model['id']}",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 2000,
            }

            if model["provider"] in ("xai", "deepseek"):
                kwargs["api_base"] = model["base_url"]

        try:
            response = await litellm.acompletion(**kwargs)
            content = response.choices[0].message.content
            claim_results = parse_gate_response(content, gate_claims)
        except Exception as e:
            # Gate failure → offline fallback
            claim_results = evaluate_claims_offline(gate_claims)

        total_calls = 1

    t_elapsed = time.monotonic() - t_start

    n_passed = sum(1 for r in claim_results if r.passed)
    n_failed = len(claim_results) - n_passed

    # Gate passes if ANY claims survived — it filters, not blocks.
    # Failed claims are removed; passed claims proceed to S4.
    overall_pass = n_passed > 0

    recommendation = ""
    if n_failed == 0:
        recommendation = (
            f"Lab Gate PASSED. {n_passed}/{n_passed} claims cleared all three criteria. "
            f"Proceeding to S4 hypothesis operationalization."
        )
    elif overall_pass:
        failed_claims = [r for r in claim_results if not r.passed]
        reasons = []
        for r in failed_claims:
            if not r.falsifiable:
                reasons.append(f"'{r.statement[:50]}...' lacks falsifiability")
            if not r.feasible:
                reasons.append(f"'{r.statement[:50]}...' not feasible")
            if not r.novel:
                reasons.append(f"'{r.statement[:50]}...' lacks novelty")

        recommendation = (
            f"Lab Gate PASSED with filter. {n_passed}/{len(claim_results)} claims cleared. "
            f"{n_failed} filtered: {'; '.join(reasons[:3])}"
        )
    else:
        recommendation = (
            f"Lab Gate FAILED. 0/{len(claim_results)} claims passed. "
            f"Route to human review."
        )

    return GateResult(
        passed=overall_pass,
        claims=claim_results,
        n_passed=n_passed,
        n_failed=n_failed,
        total_calls=total_calls,
        latency_s=round(t_elapsed, 2),
        recommendation=recommendation,
    )


def run_gate_sync(
    pipeline_result: dict,
    model_name: str = "verify",
    use_offline: bool = False,
) -> GateResult:
    """Synchronous wrapper for run_gate."""
    return asyncio.run(run_gate(pipeline_result, model_name, use_offline))
